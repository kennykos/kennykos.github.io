---
layout: post
title:  3D Morton Z-ordering for Cache-aware Near-field Interactions on a GPU
date:   2015-03-15 16:40:16
description: march & april, looking forward to summer
tags: 
categories: draft
giscus_comments: true
---

![Grid Traversal](../../../../assets/zorder/grid_traversals_2d.png){: style="max-width: 100%; height: auto;" }

# Background on $$N$$-body Simulations
Classical $$N$$-body simulations compute the *potential* $$\boldsymbol{u}(\boldsymbol{y}_j)$$ at a *source* particle $$\boldsymbol{y}_j$$ as the convolution with densities $$\boldsymbol{q}(\boldsymbol{x}_i)$$ of *target* particles $$\boldsymbol{x}_i$$. Formally, Given $$M$$ sources and $$N$$ targets, we express the $$N$$-body problem as

\begin{equation}
    \boldsymbol{u}(\boldsymbol{y}_j) = \sum_i^N K(\boldsymbol{x}_i, \boldsymbol{y}_j) \boldsymbol{q}(\boldsymbol{x_i}), \quad j = 1, \dots, M,
\end{equation}
where $$K(\boldsymbol{y}_j, \boldsymbol{x_i})$$ is some convolution kernel. When $$M=N$$, solving an $$N$$-body problem has an asymptotic complexity of $$\mathcal{O}(N^2)$$, which is prohibitively expensive for modestly large systems (say $$N=1e6$$).

The canonical $$N$$-body problem considers the *electrostatic* potential derived by setting $$K(\boldsymbol{x}_i, \boldsymbol{y}_j) = G(\|\boldsymbol{x}_i - \boldsymbol{y}_j\|)$$, where $$G(\boldsymbol{r}) = \frac1{\|\boldsymbol{r}\|}$$ is the free-space Green's function for the Laplace equation $$\Delta u = 0$$. The electrostatic problem is indicative of many $$N$$-body problems in the sense that it's convolution kernel $$G(\boldsymbol{r})$$ is singular when $$\|\boldsymbol{r}\|$$ is small and smooth (hence easy to approximate) when $$\|\boldsymbol{r}\|$$ is large. This observation leads to an operator splitting 
$$
\begin{equation}
    \boldsymbol{u}(\boldsymbol{y}_j) = \boldsymbol{u}(\boldsymbol{y}_j)^n + \boldsymbol{u}(\boldsymbol{y}_j)^f
\end{equation}
$$
common to many fast methods (Ewald [1], Barnes–Hut [2], Fast-Multipole Method [3], etc.) ,where the near-field potential $$\boldsymbol{u}^n$$ is given by some compactly supported near-field Green's function $$G^n$$ and the far-field potential $$\boldsymbol{u}^n$$ is given by some smooth far-field Greens function $$G^f$$. For example, the Fast-Multipole Method sets 
$$
\begin{equation}
G^n(\boldsymbol{r})=
\begin{cases}
G(\boldsymbol{r}) & \text{if } \|\boldsymbol{r}\| < r_c \\
0 & \text{otherwise}
\end{cases} \quad\text{ and } \quad
G^f(\boldsymbol{r})=
\begin{cases}
G(\boldsymbol{r}) & \text{if } \|\boldsymbol{r}\| >= r_c \\
0 & \text{otherwise}
\end{cases},
\end{equation}
$$
where $$r_c$$ is some fixed cutoff radius. The general idea for fast methods is that a fixed $$r_c$$ leads to $$\mathcal{O}(n)$$ cost for the near-field potential $$\boldsymbol{u}(\boldsymbol{y}_j)^n = \sum_i^N G^n(\|\boldsymbol{x}_i-\boldsymbol{y}_j\|)\boldsymbol{q}(\boldsymbol{x_i})$$ and the far-field potential $$\boldsymbol{u}(\boldsymbol{y}_j)^f = \sum_i^N G^f(\|\boldsymbol{x}_i-\boldsymbol{y}_j\|)\boldsymbol{q}(\boldsymbol{x_i})$$ remains smooth and can be approximated in $$\mathcal{O}(n)$$ or $$\mathcal{O}(n\log n)$$ time.

![Split](../../../../assets/zorder/fmm_green_split.png){: style="max-width: 100%; height: auto;" }

# Computing the Near-field

# Background on PyKokkos
...

# A Simple Parallel Near-Field code in PyKokkos
Let our computational box be defined as $$\mathcal{B} = [1,1,1]$$
and the average number of sources per cell be $$s = 64$$, and consider $$n=1e6$$ 
uniformly distributed particles. Thus, we
partition our box into $$25$$ cells ().

## Reshuffling into Cells

(TODO: insert figure here)

<!-- doing "```py" here should work, but everything is ugly and the font is wrong -->
```
import cupy as cp
import pykokkos as pk

@pk.function
def getNeighbor(cell: int, k: int) -> int:
    return cell

@pk.function
def t2c(team: int) -> int:
    return team

@pk.workunit
def near(team_member, x, y, q, u, s):
    t: int = team_member.league_rank()
    c: int = t2c(team) # team-to-cell index map
    def target_loop(i: int): #parfor
        x0: pk.doulbe = x[i][0]
        x1: pk.double = x[i][1]
        x2: pk.double = x[i][2]
        _u: pk.double = 0.0
        for k in range(27):
            off: int =  nc*getNeighbor(cell, k)
            for j in range(off, off+s):
                r0: pk.double = x0 - y[j][0]
                r1: pk.double = x1 - y[j][1]
                r2: pk.double = x2 - y[j][2]
                rsqr: pk.double = r0*r0*r1*r1*r2*r2
                rinv: pk.double = pk.rsqrt(rsqr) # fast 1/(sqrt(r))
                rinv = rinv + (rinv - rinv)
                rinv = pk.fmax(rinv, 0.0) # see [?] Lashuk et al.
                _u += rinv
        u[i] = _u


    pk.parallel_for(pk.TeamThreadRange(team_member, s), target_loop)

def main():
    # Problem setup
    n = 1000000
    box = [1,1,1]
    s = 64
    nc = n//s
    x = cp.random.uniform(size=(n,3)) # targets
    y = cp.random.uniform(size=(n,3)) # sources
    q = cp.random.uniform(size=n)     # charges
    u = cp.random.empty(size=n)       # potentials
    # Cuda kernel call
    pk.set_default_space(pk.Cuda)
    policy = pk.TeamPolicy(n_c, pk.AUTO)
    pk.parallel_for("near", policy, near, x=x, y=y, q=q, s=s)

main()
```

# References
[1] Ewald, P. P. (1921). Die Berechnung optischer und elektrostatischer Gitterpotentiale. Annalen Der Physik, 369(3), 253–287. https://doi.org/10.1002/andp.19213690304
[2] Barnes, J., & Hut, P. (1986). A hierarchical O(N log N) force-calculation algorithm. Nature, 324(6096), 446–449. https://doi.org/10.1038/324446a0
[3] Greengard, L., & Rokhlin, V. (1987). A fast algorithm for particle simulations. Journal of Computational Physics, 73(2), 325–348. https://doi.org/10.1016/0021-9991(87)90140-9